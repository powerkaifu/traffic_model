import pandas as pd
import os
import json
import joblib
from tensorflow.keras.models import load_model  # type: ignore

# è‡ªå·±çš„æ¨¡çµ„
from predictor import predict_new


def preprocess_and_scale_new_data(new_data_df: pd.DataFrame, feature_names: list, scaler):
  one_hot_vd_cols = [ col for col in feature_names if col.startswith('VD_ID_') ]
  new_data_df_processed = pd.get_dummies(new_data_df, columns = ['VD_ID'], prefix = 'VD_ID')

  # è£œé½Šç¼ºå°‘çš„ one-hot æ¬„ä½
  for col in one_hot_vd_cols:
    if col not in new_data_df_processed.columns:
      new_data_df_processed[col] = 0

  numerical_features_to_scale = [
      'Speed',
      'Occupancy',
      'Volume_M',
      'Volume_S',
      'Volume_L',
      'Volume_T',
      'Speed_M',
      'Speed_S',
      'Speed_L',
      'Speed_T',
      'DayOfWeek',
      'Hour',
      'Minute',
      'Second',
      'LaneID',
      'LaneType',
      'IsPeakHour',
  ]
  existing_numerical = [ f for f in numerical_features_to_scale if f in new_data_df_processed.columns ]
  new_data_df_processed[existing_numerical] = new_data_df_processed[existing_numerical].astype(float)

  # æ¨™æº–åŒ–
  scaled_values = scaler.transform(new_data_df_processed[existing_numerical])
  scaled_df = pd.DataFrame(scaled_values, columns = existing_numerical, index = new_data_df_processed.index)
  new_data_df_processed.loc[:, existing_numerical] = scaled_df

  # è£œé½Šæ¬„ä½é †åºä¸¦å¡« 0
  X_new_final = pd.DataFrame(0, index = new_data_df_processed.index, columns = feature_names)
  for col in feature_names:
    if col in new_data_df_processed.columns:
      X_new_final[col] = new_data_df_processed[col]

  return X_new_final.values.astype(float)


# ğŸ”§ ç‰¹å¾µé †åºï¼ˆèˆ‡è¨“ç·´æ¨¡å‹ä¸€è‡´ï¼‰
feature_names = [
    'Speed',
    'Occupancy',
    'Volume_M',
    'Volume_S',
    'Volume_L',
    'Volume_T',
    'Speed_M',
    'Speed_S',
    'Speed_L',
    'Speed_T',
    'LaneID',
    'LaneType',
    'Hour',
    'DayOfWeek',
    'Minute',
    'Second',
    'IsPeakHour',
    'VD_ID_VLRJM60',
    'VD_ID_VLRJX00',
    'VD_ID_VLRJX20',
    'Occ_x_Volume_S',
    'Occ_x_Volume_L',
    'Occ_x_Volume_T',
    'SpeedS_x_VolumeS',
    'SpeedL_x_VolumeL',
    'SpeedT_x_VolumeT'
]

# ğŸ“‚ è·¯å¾‘è¨­å®š
model_path = './traffic_models/trained_model.keras'
scaler_path = './traffic_models/scaler.pkl'
samples_path = 'sample_inputs.json'

# âœ… è¼‰å…¥æ¨¡å‹èˆ‡ scaler
model = load_model(model_path) if os.path.exists(model_path) else None
scaler = joblib.load(scaler_path) if os.path.exists(scaler_path) else None

# ğŸš¦ æ‰¹æ¬¡é æ¸¬æµç¨‹
if not all([ model, scaler ]) or not os.path.exists(samples_path):
  print("âŒ è«‹ç¢ºèªæ¨¡å‹ã€ç‰¹å¾µç¸®æ”¾å™¨èˆ‡ sample_inputs.json éƒ½å­˜åœ¨ï¼")
else:
  print("ğŸ“Œ æ‰¹æ¬¡é æ¸¬è³‡æ–™çµæœï¼š")
  with open(samples_path, 'r') as f:
    samples_inputs = json.load(f)

  for i, sample_input in enumerate(samples_inputs):
    df = pd.DataFrame([sample_input])
    X_new = preprocess_and_scale_new_data(df, feature_names, scaler)
    pred = predict_new(model, X_new)

    hour = sample_input.get('Hour', -1)
    minute = sample_input.get('Minute', -1)
    is_peak = sample_input.get('IsPeakHour', 0)
    peak_status = "å°–å³°" if is_peak == 1 else "é›¢å³°"

    print(f"ç¯„ä¾‹ {i+1}ï¼šæ™‚é–“ {hour:02d}:{minute:02d}ï¼ˆ{peak_status}ï¼‰ â†’ é æ¸¬ç¶ ç‡ˆç§’æ•¸ = {pred[0][0]:.2f} ç§’")
