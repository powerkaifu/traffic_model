import pandas as pd
import os
import json
import joblib
import numpy as np  # æ–°å¢å°å…¥ numpy
from tensorflow.keras.models import load_model  # type: ignore

# è‡ªå·±çš„æ¨¡çµ„
# from predictor import predict_new # å‡è¨­ä½ çš„ predict_new æœƒè¿”å›åŸå§‹é æ¸¬å€¼


# å®šç¾©ä¸€å€‹å¸¶æœ‰è£å‰ªé‚è¼¯çš„é æ¸¬å‡½æ•¸
def predict_with_clipping(model, X_new_data, min_val = 30.0, max_val = 99.0):
  """
    ä½¿ç”¨æ¨¡å‹é€²è¡Œé æ¸¬ï¼Œä¸¦å°‡çµæœè£å‰ªåˆ°æŒ‡å®šç¯„åœå…§ã€‚
    """
  predicted_green_seconds_raw = model.predict(X_new_data)

  # å°æ¯å€‹é æ¸¬å€¼é€²è¡Œè£å‰ª
  clipped_green_seconds = np.clip(predicted_green_seconds_raw, min_val, max_val)

  # å››æ¨äº”å…¥ä¸¦è½‰æ›ç‚ºæ•´æ•¸
  final_green_seconds = np.round(clipped_green_seconds).astype(int)

  return final_green_seconds


# ä½ çš„ preprocess_and_scale_new_data å‡½æ•¸ (ä¿æŒä¸è®Š)
def preprocess_and_scale_new_data(new_data_df: pd.DataFrame, feature_names: list, scaler):
  one_hot_vd_cols = [ col for col in feature_names if col.startswith('VD_ID_') ]
  new_data_df_processed = pd.get_dummies(new_data_df, columns = ['VD_ID'], prefix = 'VD_ID')

  # è£œé½Šç¼ºå°‘çš„ one-hot æ¬„ä½
  for col in one_hot_vd_cols:
    if col not in new_data_df_processed.columns:
      new_data_df_processed[col] = 0

  numerical_features_to_scale = [
      'Speed',
      'Occupancy',
      'Volume_M',
      'Volume_S',
      'Volume_L',
      'Volume_T',
      'Speed_M',
      'Speed_S',
      'Speed_L',
      'Speed_T',
      'DayOfWeek',
      'Hour',
      'Minute',
      'Second',
      'LaneID',
      'LaneType',
      'IsPeakHour',
  ]
  existing_numerical = [ f for f in numerical_features_to_scale if f in new_data_df_processed.columns ]
  new_data_df_processed[existing_numerical] = new_data_df_processed[existing_numerical].astype(float)

  # æ¨™æº–åŒ–
  scaled_values = scaler.transform(new_data_df_processed[existing_numerical])
  scaled_df = pd.DataFrame(scaled_values, columns = existing_numerical, index = new_data_df_processed.index)
  new_data_df_processed.loc[:, existing_numerical] = scaled_df

  # è£œé½Šæ¬„ä½é †åºä¸¦å¡« 0
  X_new_final = pd.DataFrame(0, index = new_data_df_processed.index, columns = feature_names)
  for col in feature_names:
    if col in new_data_df_processed.columns:
      X_new_final[col] = new_data_df_processed[col]

  return X_new_final.values.astype(float)


# ğŸ”§ ç‰¹å¾µé †åºï¼ˆèˆ‡è¨“ç·´æ¨¡å‹ä¸€è‡´ï¼‰
feature_names = [
    'Speed',
    'Occupancy',
    'Volume_M',
    'Volume_S',
    'Volume_L',
    'Volume_T',
    'Speed_M',
    'Speed_S',
    'Speed_L',
    'Speed_T',
    'LaneID',
    'LaneType',
    'Hour',
    'DayOfWeek',
    'Minute',
    'Second',
    'IsPeakHour',
    'VD_ID_VLRJM60',
    'VD_ID_VLRJX00',
    'VD_ID_VLRJX20',
    'Occ_x_Volume_S',
    'Occ_x_Volume_L',
    'Occ_x_Volume_T',
    'SpeedS_x_VolumeS',
    'SpeedL_x_VolumeL',
    'SpeedT_x_VolumeT'
]

# ğŸ“‚ è·¯å¾‘è¨­å®š
model_path = './traffic_models/trained_model.keras'
scaler_path = './traffic_models/scaler.pkl'
samples_path = 'sample_inputs.json'

# âœ… è¼‰å…¥æ¨¡å‹èˆ‡ scaler
model = load_model(model_path) if os.path.exists(model_path) else None
scaler = joblib.load(scaler_path) if os.path.exists(scaler_path) else None

# ğŸš¦ æ‰¹æ¬¡é æ¸¬æµç¨‹
if not all([ model, scaler ]) or not os.path.exists(samples_path):
  print("âŒ è«‹ç¢ºèªæ¨¡å‹ã€ç‰¹å¾µç¸®æ”¾å™¨èˆ‡ sample_inputs.json éƒ½å­˜åœ¨ï¼")
else:
  print("ğŸ“Œ æ‰¹æ¬¡é æ¸¬è³‡æ–™çµæœï¼š")
  with open(samples_path, 'r') as f:
    samples_inputs = json.load(f)

  for i, sample_input in enumerate(samples_inputs):
    df = pd.DataFrame([sample_input])
    X_new = preprocess_and_scale_new_data(df, feature_names, scaler)

    # é€™è£¡èª¿ç”¨æ–°çš„é æ¸¬å‡½æ•¸ï¼Œå®ƒæœƒè™•ç†è£å‰ª
    pred_clipped = predict_with_clipping(model, X_new, min_val = 20.0, max_val = 99.0)

    hour = sample_input.get('Hour', -1)
    minute = sample_input.get('Minute', -1)
    is_peak = sample_input.get('IsPeakHour', 0)
    peak_status = "å°–å³°" if is_peak == 1 else "é›¢å³°"

    # pred_clipped çš„å½¢ç‹€æ˜¯ (1, 1)ï¼Œæ‰€ä»¥å–å€¼æ˜¯ pred_clipped[0][0]
    print(f"ç¯„ä¾‹ {i+1}ï¼šæ™‚é–“ {hour:02d}:{minute:02d}ï¼ˆ{peak_status}ï¼‰ â†’ é æ¸¬ç¶ ç‡ˆç§’æ•¸ = {pred_clipped[0][0]:.0f} ç§’")  # æ”¹ç‚º .0f é¡¯ç¤ºæ•´æ•¸
