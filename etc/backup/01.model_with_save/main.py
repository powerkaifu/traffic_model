import pandas as pd
from sklearn.model_selection import train_test_split
from data_process import combine_vd_dataframes, preprocess_data
from predictor import build_model, train_model, evaluate_model, predict_new
import tensorflow as tf
from tensorflow.keras.models import load_model  # type: ignore
import os

# print(tf.__version__) # 2.19.0
pd.set_option('display.width', None)
pd.set_option('display.max_columns', None)

# è¨­å®š VD è³‡æ–™å¤¾å’Œæª”æ¡ˆåç¨±
base_dir = "."
vd_folders = [ 'VLRJM60', 'VLRJX00', 'VLRJX20']
# Week 1
# date_file = '2025-02-17_2025-02-23.json'
# Week 2
# date_file = '2025-02-24_2025-03-02.json'
# Week 3
# date_file = '2025-03-03_2025-03-09.json'
# Week 4
# date_file = '2025-03-10_2025-03-16.json'
# Week 5
# date_file = '2025-03-17_2025-03-23.json'
# Week 6
# date_file = '2025-03-24_2025-03-30.json'
# Week 7
date_file = '2025-03-31_2025-04-06.json'

# è®€å–ä¸¦åˆä½µ VD è³‡æ–™
merged_df = combine_vd_dataframes(base_dir, vd_folders, date_file)
print(f"åˆä½µå¾Œçš„ DataFrame ç¸½æ¬„ä½ç­†æ•¸ï¼š{len(merged_df)}")

if merged_df is not None:
  print("åˆä½µå¾Œçš„ DataFrame è³‡æ–™æ¬„ä½ï¼š")
  print(merged_df.head(1))
  print("================================================================================")

  # å›å‚³ X å’Œ y
  X, y = preprocess_data(merged_df)
  print("è¨“ç·´è³‡æ–™ï¼š", X[0])
  print("================================================================================")

  # è½‰æ›å‹åˆ¥
  X = X.astype(float)
  y = y.astype(float)
  print("æŸ¥çœ‹ X å’Œ y çš„è³‡æ–™å‹æ…‹ï¼š")
  print(type(X), X.dtype)
  print(type(y), y.dtype)
  print("X ç‰¹å¾µè³‡æ–™é›†ï¼š")
  print(X[0])
  print("y ç›®æ¨™è®Šæ•¸è³‡æ–™é›†ï¼š")
  print(y[0])
  print("================================================================================")

  # åˆ†å‰²è¨“ç·´èˆ‡æ¸¬è©¦é›†
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

  # å˜—è©¦è¼‰å…¥æ¨¡å‹ï¼›è‹¥å¤±æ•—å‰‡å»ºç«‹æ–°æ¨¡å‹
  # model_path = 'trained_model.h5'
  model_path = './traffic_models/trained_model.h5'

  try:
    if os.path.exists(model_path):
      model = load_model(model_path, custom_objects = { 'mse': tf.keras.losses.MeanSquaredError})
      print("âœ… å·²åŠ è¼‰å…ˆå‰è¨“ç·´çš„æ¨¡å‹")
      model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mse')
    else:
      raise FileNotFoundError("æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
  except Exception as e:
    print(f"âš ï¸ è¼‰å…¥æ¨¡å‹å¤±æ•—ï¼ŒåŸå› ï¼š{e}")
    model = build_model(input_shape = X.shape[1])
    print("ğŸ†• å»ºç«‹æ–°çš„æ¨¡å‹")

  # ä½¿ç”¨æ–°è³‡æ–™ç¹¼çºŒè¨“ç·´æ¨¡å‹
  train_model(model, X_train, y_train, epochs = 50)

  # å„²å­˜æ¨¡å‹
  model.save(model_path)
  print("âœ… æ¨¡å‹å·²ä¿å­˜")

  # é æ¸¬èˆ‡ç¯©é¸
  startIndex = 0
  endIndex = 4547
  over_seconds = 40
  y_pred = evaluate_model(model, X_test, y_test)
  new_pred = predict_new(model, X_test[startIndex : endIndex])
  print("æ–°è³‡æ–™é æ¸¬çµæœï¼š")
  print(new_pred)
  print("================================================================================")

  print(f"é æ¸¬ç¶ ç‡ˆç§’æ•¸å¤§æ–¼ {over_seconds} ç§’çš„è³‡æ–™ï¼š")
  over = [(startIndex + i, pred[0]) for i, pred in enumerate(new_pred) if pred[0] > over_seconds]
  for idx, val in over:
    print(f"ç´¢å¼• {idx}ï¼Œé æ¸¬ç¶ ç‡ˆç§’æ•¸ï¼š{val:.1f}")
else:
  print("âŒ æ²’æœ‰è®€å–åˆ°ä»»ä½• VD çš„è³‡æ–™ã€‚")
