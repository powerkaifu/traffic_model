# shap_utils.py
import os
import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt


def explain_shap_feature(model, X_train, X_test, feature_names, output_dir = "shap", nsamples = 100):
  try:
    print("ğŸ“Š é–‹å§‹ä½¿ç”¨ SHAP KernelExplainer è¨ˆç®—ç‰¹å¾µé‡è¦æ€§...")
    os.makedirs(output_dir, exist_ok = True)

    # ç”¨éƒ¨åˆ†æ¸¬è©¦è³‡æ–™ä½œç‚ºæ¨£æœ¬
    X_sample = pd.DataFrame(X_test[: 100], columns = feature_names)

    # ä½¿ç”¨è¨“ç·´è³‡æ–™ä¸­éš¨æ©Ÿ 100 ç­†ä½œç‚ºèƒŒæ™¯è³‡æ–™
    background_size = X_train.shape[0] // 200  # å–è¨“ç·´è³‡æ–™ 1/ 200 ä½œç‚ºèƒŒæ™¯è³‡æ–™å¤§å°

    background = X_train[np.random.choice(X_train.shape[0], background_size, replace = False)]

    # å®šç¾©æ¨¡å‹é æ¸¬å‡½æ•¸
    def model_predict(data_as_numpy):
      return model.predict(data_as_numpy).flatten()

    # åˆå§‹åŒ– SHAP è§£é‡‹å™¨ä¸¦è¨ˆç®— shap å€¼
    explainer = shap.KernelExplainer(model_predict, background)
    shap_values = explainer.shap_values(X_sample, nsamples = nsamples)

    # SHAP æ¢å½¢åœ–
    shap.summary_plot(shap_values, X_sample, plot_type = "bar", show = False)
    plt.savefig(f"{output_dir}/shap_feature_importance_bar.png")
    plt.clf()

    # SHAP èœ‚ç¾¤åœ–
    shap.summary_plot(shap_values, X_sample, show = False)
    plt.savefig(f"{output_dir}/shap_feature_importance_beeswarm.png")
    plt.clf()

    # è¨ˆç®—ç‰¹å¾µé‡è¦æ€§ä¸¦åˆ—å°å‰20å
    mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)
    feature_importance_df = pd.DataFrame({ 'feature': feature_names, 'mean_abs_shap_value': mean_abs_shap}).sort_values(by = 'mean_abs_shap_value', ascending = False).reset_index(drop = True)

    print("\nğŸ“ SHAP ç‰¹å¾µé‡è¦æ€§ï¼ˆå¹³å‡çµ•å° SHAP å€¼ï¼‰æ’åºï¼ˆå‰20åï¼‰ï¼š")
    print(feature_importance_df.head(20))
    print(f"âœ… SHAP åœ–å·²å„²å­˜è‡³ '{output_dir}' è³‡æ–™å¤¾")

    return feature_importance_df

  except Exception as e:
    print("âŒ SHAP è§£é‡‹å¤±æ•—ï¼ŒåŸå› ï¼š", e)
    return None
